{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os #para manejo de archivos\n",
    "import skimage.data as imd #un sklearn para imagenes\n",
    "import numpy as np\n",
    "import datetime #informacion con el tiempo de TF\n",
    "import matplotlib.pyplot as plt #para graficar\n",
    "### ===== para tratar las imagenes\n",
    "from skimage import transform #para redimensionar las imagenes\n",
    "from skimage.color import rgb2gray#convertir a espacio de color gris. (hay muchos mas como rojo, verde, azul)\n",
    "\n",
    "import random #aleatory num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para importar los datos ==============================\n",
    "def load_ml_data(data_directory):#recibo la ruta de los datos\n",
    "    dirs = [d for d in os.listdir(data_directory)\n",
    "           if os.path.isdir(os.path.join(data_directory,d))]#voy pasando item por item de cada directoriolisto todos los directorios que se pueden obtener a partir de data_directory\n",
    "    \n",
    "    #print(dirs)#muestro directorios DEBUG\n",
    "    \n",
    "    labels = [] #array de etiquetas para las fotos\n",
    "    images = [] #el archivo de imagen en si\n",
    "    for d in dirs:\n",
    "        label_dir = os.path.join(data_directory, d)#entro a cada carpetica en la lista dirs\n",
    "        file_names = [os.path.join(label_dir,f) #reviso cada item del directorio SI es un archivo de imagen lo guardo \n",
    "                     for f in os.listdir(label_dir)   \n",
    "                     if f.endswith(\".ppm\")]\n",
    "        #----------DEBUG\n",
    "        #print(label_dir)#directorios\n",
    "        #print(\"\\n\")\n",
    "        #print(file_names)#nombres de archivo dentro de ese directorio (cada una de las fotos)\n",
    "        \n",
    "        #--- Vamos a recorrer las imagenes\n",
    "        for f in file_names:\n",
    "            images.append(imd.imread(f))#leo imagen y la agrego a images conm el formato de datos para skimage\n",
    "            labels.append(int(d))#numeros enteros para los labels\n",
    "            \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"../datasets/belgian/\" #directorio principipal\n",
    "train_dir = os.path.join(main_dir, \"Training\") #Directorio de entrenamiento\n",
    "test_dir = os.path.join(main_dir, \"Testing\") #directorio de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = load_ml_data(train_dir)#X_train = imagenes Y_train =labels\n",
    "X_test, Y_test = load_ml_data(test_dir)#X_train = imagenes Y_train =labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_dataset(dataxy):\n",
    "    print(\"longitud: \", len(dataxy))\n",
    "    print(\"Tipo: \", type(dataxy))\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dataset(X_train)#informacion de imagenes train\n",
    "info_dataset(Y_train)#labels train\n",
    "info_dataset(X_test)#informacion de imagenes test\n",
    "info_dataset(Y_test)#labels test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debo convertir esos datos en \"Datasets\" o arrays de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img_train = np.array(X_train)\n",
    "Y_lbl_train = np.array(Y_train)\n",
    "X_img_test = np.array(X_test)\n",
    "Y_lbl_test = np.array(Y_test)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_img_train.ndim, Y_lbl_train.ndim) #1 dimension = 1 columna\n",
    "print(X_img_test.ndim, Y_lbl_test.ndim)\n",
    "print(X_img_train.size, Y_lbl_train.size)#1 etiqueta para cada imagen\n",
    "print(X_img_test.size, Y_lbl_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_img_train[0] #primera foto en formato array, las fotos son valores (los colores - 3 canales y arrays corresponden a cada pixel)\n",
    "#Es un array de arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(Y_lbl_train))#cuantas etiquetas UNICAS hay? set solo cuenta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_imagen(imgs):\n",
    "    print(\"Datos iniciales de imagen: \", imgs.flags)\n",
    "    print(\"Itemsize:\", imgs.itemsize)#elementos en cuantos bits?\n",
    "    print(\"# de bytes: \", imgs.nbytes)\n",
    "    print(\"Bytes que uso:\", imgs.nbytes/imgs.itemsize) #las bytes que estoy utilizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_imagen(X_img_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Y_lbl_train, len(set(Y_lbl_train)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frecuencia de las etiquetas (cuantas fotos hay por cada señal)**\n",
    "* Vimos que no todos los tipos de imagenes estan igual de representadas en el dataset\n",
    "* La red neuronal aprende que a mayor cantidad de señales esta sera mas importante\n",
    "    * Cuidado con ello, la red tirara ante una duda a la mas probable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen visual de las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_signs = random.sample(range(0,len(Y_lbl_train)),6)#quiero una muestra aleatoria simple\n",
    "rand_signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinto las imagenes random **extraidas de mi carpeta de entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_random(random_img,dtset_evaluado):#dataset evaluado recibe el conjunto de imagenes (el completo) sobre el cual vamos a iterar\n",
    "    for i in range(len(rand_signs)):\n",
    "        temp_img = dtset_evaluado[rand_signs[i]]#imagen actual \n",
    "        plt.subplot(1,6,i+1)#dibujo 6 columnas (6 fotitos)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(temp_img)#muestro las imagenes \n",
    "        plt.subplots_adjust(wspace=0.5)#espacio para que las imagenes no salgan muy pegadas\n",
    "\n",
    "        plt.show()#muestro\n",
    "\n",
    "        #la sigueinte notacion viene de Django, me permite poner parametros al texto que se encuentra numerado entre las llaves\n",
    "        print(\"Forma: {0}, Min: {1}, Max:{2}\".format(temp_img.shape,#altura y ancho\n",
    "                                                     temp_img.min(),#pixel con menor color\n",
    "                                                     temp_img.max()))#pixel con mas color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random(rand_signs, X_img_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA**\n",
    "* Cuidado con los tamaños\n",
    "    * Si la IA se fija en parametros maximos y minimos no va a ser muy efeciciente y para una misma señal hay colores diferentes\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voy a mostrar las imagenes con sus identificadores**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set(Y_lbl_train)#etiquetas unicas\n",
    "plt.figure(figsize=(16,16))#tamaño de la figura aqui\n",
    "i=1\n",
    "for label in unique_labels:\n",
    "    temp_img = X_img_train[list(Y_lbl_train).index(label)]#me quedo con la imagen en la posicion del indice NO en el indice\n",
    "    #se convierte en lista para poder usar la propiedad index\n",
    "    #con esa posicion busco la imagen de la cual procede\n",
    "    plt.subplot(8,8,i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Clase {0} ({1})\".format(label,list(Y_lbl_train).count(label)))\n",
    "    i+=1 #manejo contador\n",
    "    plt.imshow(temp_img)#muestro imagen en bucle\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lo que esta pasando?**\n",
    "Me esta mostrando para cada imagen (la clase unica) cuantos ejemplos hay. entonces por ejemplo de la clase 22 hay 375 imagenes de ejemplo\n",
    "\n",
    "**¿El hecho de que haya mas señales de un tipo indica algun patron?**\n",
    "        --->>> parece que no tienen un patron de seguimiento\n",
    "* Primera pregunta curiosa\n",
    "* X es tan freceunte que ante una duda podria elegir la que mas ejemplos tiene?\n",
    "* **Debemos intentar averiguar lo mas posible del problema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado de imagenes previo al ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de red neuronal con TensorFlow\n",
    "* No todas las imagenes son del mismo tamaño\n",
    "* Hay 62 clases de imagenes (de 0 a 61)\n",
    "* La distribucion de señales de trafico NO es uniforme, algunas salen mas veces que otras\n",
    "    * No hay ninguna relacion de importancia con ello. Solo hay mas fotos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Que vamos a hacer ahora?**\n",
    "1. iniciemos por obtener algunos rasgos de nuestras imagenes\n",
    "    * Las reescalaremos\n",
    "    * convertimos a escala de grises **utilizar el color como regla de decisión es poco util, resulta perjudicial para la red neuronal, en la mayoria de casos el color no es el principal parametro** _el nivel de iluminacion influye de formas impredecibles_ hay fotos muy oscuras y fotos con muchisima luz. \n",
    "    \n",
    "    * _reescalar las imagenes es un problema importante_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deseo conocer el tamaño de imagen mas pequeño que me puedo encontrar\n",
    "w = 9999\n",
    "h = 9999\n",
    "for image in X_img_train:#paso por todas las imagenes. El tamaño minimo puede ser combinacion de dos fotos diferentes\n",
    "    if image.shape[0] < h:\n",
    "        h = image.shape[0]\n",
    "    if image.shape[1] < w:\n",
    "        w = image.shape[1]\n",
    "print (\"tamaño minimo: {0},{1}\".format(h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#doy tamaño 30x30 a todas las imagenes de la carpeta de entrenamiento. las mas pequeñas las hara mas grandes\n",
    "X_img_train30 = [transform.resize(image,(30,30)) for image in X_img_train]\n",
    "X_img_train30[0]#los valores cambiaron --> ahora tiene 900 pixeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#revisamos nuevamente el tamaño, ahora con el cambio aplicado\n",
    "rand_signs = random.sample(range(0, len(Y_lbl_train)), 6)#genero aleatorio\n",
    "data_random(rand_signs,X_img_train30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Una buena noticia**\n",
    "No necesitaremos normalizar los datos. Como casi todos estos datos inician en 0 y acaban en 1 tenemos un dataset muy uniforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img_train30 = np.array(X_img_train30) #tamaño y tipo de dato correcto para skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img_train30 = rgb2gray(X_img_train30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_signs = random.sample(range(0, len(Y_lbl_train)), 6)\n",
    "data_random(rand_signs,X_img_train30)\n",
    "#para que se vea gris agrega esta linea a la funcion inicialmente definida:\n",
    "#plt.imshow(temp_im, cmap=\"gray\")#especifico la temperatura de color igualmente (SI NO se ve como azul con amarillo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Vale la pena consulta tecnicas de preprocesado con skimage**\n",
    "TensorFlow no es el unico paquete para manipulacion de imagenes, tambien esta Keras. pero TensorFlow es muy conocido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion de mi propia red neuronal\n",
    "Voy a crear una red neuronal usando tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construccion de la RNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo basado en _Sequential()_ indica una capa detras de la otra que van a ser rellenadas con capas totalemnte conectadas\n",
    "\n",
    "* Se van a calcular una detras de la otra en secuencia\n",
    "\n",
    "Hyper-parametros de la capa:\n",
    "\n",
    "* número de unidades/neuronas: 130 \n",
    "* función de activación: ReLU _0 si el valor el negativo, de lo contrario se queda con el valor actual_\n",
    "* input_shape: (30,30) _esto tiene correspondencia directa con el tamaño de imagen 30*30_\n",
    "\n",
    "#### Capa DropOut\n",
    "Dropout es una técnica de Regularization donde aleatoriamente se asignan a ciertas neuronas de la red el valor cero. De este modo, mientras se entrena, estas neuronas no actualizarán sus valores. Al tener cierto porcentaje de neuronas sin actualizar, el proceso de entrenamiento toma más tiempo pero por contra tenemos menos posibilidades de sufrir overfitting.\n",
    "\n",
    "* Significa que en el fase de entrenamiento (propagacion hacia atras) los valores no se van a actualizar\n",
    "\n",
    "* Estaran dormidas, como no se actualizan cierto porcentaje de ellas conservan sus valores iniciales sin retroalimentarse\n",
    "\n",
    "* Los valores de DropOut tipicamente estan entre 20% y 50%\n",
    "\n",
    "#### Añadir la segunda capa (capa de salida)\n",
    "* Unidades: número de clases (62 tipos de señal) \n",
    "* función de activación: 'softmax' (probabilidades de cada clase) _devuelve probabilidad de cual (cuan % esta seguro)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(30,30))) #capa de aplanado que recibe 900 pixeles 30*30 c/u de las imagenes\n",
    "model.add(tf.keras.layers.Dense(units=130, activation=\"relu\")) #activador relu, 130 neuronas\n",
    "model.add(tf.keras.layers.Dense(units=256, activation=\"sigmoid\"))#nueva capa para mejorar efectividad\n",
    "model.add(tf.keras.layers.Dropout(0.2)) #capa DropOut, 20% NO aprende. Esto para mejorar su eficacia con datos diferentes a los de test\n",
    "model.add(tf.keras.layers.Dense(units=62, activation='softmax'))\n",
    "#capa de salida, 32 diferentes categorias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Optimizer: Adam _uno de los mejores optimizadores de gradiente descendiente estocastico **es el recomendado por defecto**_\n",
    "* Loss: Sparse softmax (categorical) crossentropy. _Es decir como va a calcular el error entre la prediccion y la categoria real_\n",
    "* metrics = \"sparse_categorical_accuracy\", me permite conocer los porcentajes de acierto o eficacia. Como su nombre lo indica me permite medir esto teniendo en cuenta las categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() #resumen de los datos de mi modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_img_train30, Y_lbl_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar sobre el conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA IMPORTANTE**\n",
    "Antes de evaluar vamos a tratar las imagenes del dataset de evaluacion. **Debemos hacerlas tambien en escala de grises y de 30x30**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doy tamaño 30x30 a todas las imagenes de la carpeta de evaluación. las mas pequeñas las hara mas grandes\n",
    "X_img_test30 = [transform.resize(image,(30,30)) for image in X_img_test]\n",
    "#X_img_test30[0]#los valores cambiaron --> ahora tiene 900 pixeles\n",
    "X_img_test30 = np.array(X_img_test30) #tamaño y tipo de dato correcto para skimage\n",
    "X_img_test30 = rgb2gray(X_img_test30)#color gris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La celda anterior ejecuto las tareas necesarias para dejar nuestras imagenes de tamaño 30*30, en escala de grises y en el tipo de archivo indicado para skimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora si, sin mas a evaluar sobre test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_img_test30, Y_lbl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Primera tirada** _loss: 0.3294 - sparse_categorical_accuracy: 0.8484_\n",
    "* con 10 eponcn ---> 0s 82us/sample - loss: 0.4921 - sparse_categorical_accuracy: 0.8903\n",
    "\n",
    "DATOS DE LA PRUEBA\n",
    "Model: \"sequential\"\n",
    "1. Flatten\n",
    "2. Dense - 130 neuronas  - 117130 parametros (relu)\n",
    "3. Droput al 20%         \n",
    "4. Dense_1 (salida,62)   - 8122 parametros\n",
    "Total params: 125,252\n",
    "Trainable params: 125,252\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "\n",
    "**Segunda tirada** _loss: 0.3257 - sparse_categorical_accuracy: 0.8532_\n",
    "* con 10 eponcn ---> loss: 0.4921 - sparse_categorical_accuracy: 0.8643\n",
    "\n",
    "DATOS DE LA PRUEBA\n",
    "Model: \"sequential\"\n",
    "1. Flatten\n",
    "2. Dense - 130 neuronas  - 117130 parametros\n",
    "3. Dense_2 - 256 neuronas - 33536  (sigmoid)\n",
    "4. Droput al 20%         \n",
    "5. Dense_1 (salida,62)   - 8122 parametros\n",
    "Total params: 166,600\n",
    "Trainable params: 166,600\n",
    "Non-trainable params: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones.\n",
    "**Esta es la primera red neuronal que realizo yo mismo**. Me siento emocionado como con mi primer hola mundo.\n",
    "Recuerda que para realizarlo consultamos el documento de este mismo repositorio: \"T11 - 2 - Señales de tráfico\" que **se encuentra desactualizado** asi que lo reestructure un poco.\n",
    "* Todo el codigo sobre la red neuronal debio cambiarse a Tf2\n",
    "* el codigo para tratar y extraer los datos no sufrio mayores cambios\n",
    "* El documento de google Colab, tambien de mi autoria me ayudo a hacerlo:\n",
    "    https://colab.research.google.com/drive/1YbbCby9UenInTJM2L58E8w3x_vnK6e5A - archivo de mi autoria\n",
    "    https://colab.research.google.com/drive/1lli5-7sjp3MOCF967hfLPkL6IoAzAMQV * archivo que hice al ver las clases del curso Tf2 de udemy\n",
    "* **La documentacion de tf2 fue de enorme ayuda**\n",
    "https://www.tensorflow.org/tutorials/keras/classification\n",
    "* Otro documento para hacerlo con una red neuronal convuncional esta aqui:\n",
    "    * **lo intentaremos muy pronto**\n",
    "    https://www.tensorflow.org/tutorials/images/classification\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones\n",
    "intentemos realizar predicciones sobre el conjunto de test y veamos que sucede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = model.predict(X_img_test30)#el modelo ha predecido la clase para cada imagen del set de testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numA = random.randrange(len(X_img_test30))#un numero aleatorio entre 0 y 2520 (total valores en test)\n",
    "numA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones[numA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una prediccion esta formada por el conjunto de todas las probabilidades. En este caso con 62 diferentes etiquetas. Tenemos 6 probabilidades diferentes.\n",
    "* La mas alta es la elegida. _Se puede ver con np.argmax_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predicciones[numA]) #devuelve la etiqueta con mas probabilidad (la etiqeuta predecida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_lbl_test[numA] #Muestra la etiqueta REAL que tiene esa imagen en nuestro dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinando las etiquetas de test muestra que esta clasificaion es correcta pues el valor devuelto es el mismo tanto en prediccion como en nuestro dataset\n",
    "* Puede darse el caso de que no coincidan. Recuerda que la red tiene solo un 85% de efectividad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficar\n",
    "Conjunto aleatorio de 10 imagenes de test para evaluar de forma grafica y comprobar su efectividad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo_idx = random.sample(range(len(X_img_test30)), 10)#10 numero aleatorios en rango de imagenes\n",
    "ejemplo_images = [X_img_test30[i] for i in ejemplo_idx]#toma esas 10 imagenes aleatorias\n",
    "ejemplo_labels = [Y_lbl_test[i] for i in ejemplo_idx]#labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))#tamaño de imagen\n",
    "for i in range(len(ejemplo_images)): #recorro las imagenes obtenidas\n",
    "    verdadero = ejemplo_lables[i]\n",
    "    predice = model.predict(ejemplo_images)\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.axis(\"off\")\n",
    "    color = \"green\" if verdadero == predict else \"red\"\n",
    "    plt.text(40,15, \"Real:      {0}\\nPredicción:{1}\".format(verdad,predice), fontsize=14, color = color)\n",
    "    plt.imshow(ejemplo_images[i], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
